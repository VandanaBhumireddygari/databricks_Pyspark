```markdown
# PySpark Transformation Functions Reference

This document provides a comprehensive, function-level overview of PySpark transformation commands, covering standard Data Frame operations, aggregations, joins, and window functions, as detailed in the master class sources.

---

## 1. Core Principles and Execution

| Concept | Description | Sources |
| :--- | :--- | :--- |
| **Lazy Evaluation** | PySpark does not immediately execute transformation commands. Instead, it creates an **optimized logical plan**. Execution is triggered only when an **action** (or trigger) is called, such as `.show()`, `.display()`, or `.collect()`. | |

---

## 2. Column Manipulation and Type Casting

| Function | Purpose | Syntax/Usage Notes | Sources |
| :--- | :--- | :--- | :--- |
| **`select`** | Retrieves a subset of columns. It is **exactly same as the select command in SQL**. | Can use column name strings or the `col()` object. | |
| **`col("name")`** | The column object; provides a standardized approach, often required before applying functions or aggregation. | `df.select(col("item"))` | |
| **`.alias("name")`** | Renames a column output during a selection (similar to SQL `AS`). | Must be used with the `col()` object: `col("item").alias("Item ID")`. | |
| **`withColumnRenamed`** | Changes a column's name at the **Data Frame level**. | `df.withColumnRenamed("old", "new")`. | |
| **`withColumn`** | Creates a **new column** or **modifies an existing column** (if the existing name is provided). | Requires a transformation (e.g., calculations or `lit()`). | |
| **`lit("value")`** | Used within `withColumn` to store a **constant value** in a new column. | `df.withColumn("flag", lit("NEW"))`. | |
| **`regexp_replace`** | Replaces specified values within a string column (e.g., replacing "regular" with "R"). | Often nested within `withColumn`: `regexp_replace(col, "old", "new")`. | |
| **`col().cast(DataType())`** | Converts a column's data type (type casting) from one type (e.g., Double) to another (e.g., `StringType()`). | `col("weight").cast(StringType())`. | |
| **`df.drop("col")`** | Eliminates one or multiple columns from the Data Frame. | `df.drop("col1", "col2")`. | |

---

## 3. Data Filtering and Conditioning

| Function | Purpose | Syntax/Usage Notes | Sources |
| :--- | :--- | :--- | :--- |
| **`filter` / `where`** | Used for **row-level slicing** based on specified conditions. | `df.filter(col("col") == "value")`. | |
| **Boolean Expressions** | Combines multiple conditions using the **AND operator (`&`)**. | Each condition must be **encapsulated in parentheses** when combined: `(cond1) & (cond2)`. | |
| **`.is in("v1", "v2")`** | Filters records where a column value matches any value in a defined list (e.g., Tier 1 or Tier 2). | `col("location").is in("Tier 1", "Tier 2")`. | |
| **`.is null()`** | Filters records where a column contains null values. | `col("size").is null()`. | |
| **`when().then().otherwise()`** | Creates conditional columns (flags), similar to the **SQL `CASE WHEN` statement**. | Allows chaining of multiple `.when()` conditions before the final `.otherwise()`. | |
| **`df.dropna()`** | Drops records containing null values (NA). | `how="any"` (if any column is null) or `how="all"` (if all columns are null). Use `subset=["col"]` to target specific columns. | |
| **`df.fillna("value")`** | Replaces null values with a specified value (e.g., "Not Available"). | Use `subset=["col"]` to fill nulls only in the specified column(s). | |

---

## 4. Data Arrangement and Duplication

| Function | Purpose | Syntax/Usage Notes | Sources |
| :--- | :--- | :--- | :--- |
| **`sort` / `orderBy`** | Arranges Data Frame records. Both terms are interchangeable. | | |
| **Sorting Direction** | `.desc()` for descending order. `.asc()` for ascending order (default if none is specified). | Use `col().desc()` when sorting requires the column object. | |
| **Multiple Keys** | Sorts based on a list of columns. Order is controlled by the **`ascending`** parameter. | `ascending` requires a list of Booleans (or `0` for DESC, `1` for ASC). | |
| **`df.limit(n)`** | Restricts the Data Frame output to the first `n` records. | Similar to the **`head` function in Pandas** or **`LIMIT` in SQL**. | |
| **`dropDuplicates`** | Removes duplicate rows. Supports removing duplicates based on all columns or a **`subset`** of columns. | The version with the underscore (`drop_duplicates`) is similar to Pandas. | |
| **`distinct`** | Performs the same function as `dropDuplicates` when checking all columns (without a subset). | Similar to SQL `DISTINCT`. | |
| **`union`** | Stacks two Data Frames vertically based on **column order**. | Can mess up data if column order is different. | |
| **`unionByName`** | Stacks Data Frames vertically by aligning records based on **matching column names**, regardless of order. | This function is **not available in all languages** and is recommended for data integrity. | |

---

## 5. Aggregation and Grouping

| Function | Purpose | Syntax/Usage Notes | Sources |
| :--- | :--- | :--- | :--- |
| **`df.groupBy("col")`** | Aggregates data based on the grouping column(s). | The order of columns matters when grouping multiple fields. | |
| **`.agg(function())`** | Applies one or multiple aggregation functions (e.g., `sum`, `avg`) after grouping. | Multiple aggregation functions can be combined in one statement. | |
| **`collect_list(col)`** | Aggregates associated values into a **list (array)** instead of a numerical result. | Alternative to the function called **`group Con cat` available in MySQL**. | |
| **`.pivot("col").agg()`** | Creates a cross-tabulated output (like an Excel pivot) for data analysis. | Requires grouping the row entities first, then defining the pivot column, followed by an aggregation (e.g., `.sum()` or `.avg()`). | |

---

## 6. Joins

Joins are critical for combining two Data Frames based on a **joining key** (or joining column).

| Join Type | Architecture / Output | Sources |
| :--- | :--- | :--- |
| **Inner Join** | Returns only the records where the joining key values are **common in both** Data Frame 1 and Data Frame 2. | |
| **Left Join** | **Prioritizes the left Data Frame**. Returns all matching records plus **all remaining records from the left Data Frame**. Non-matching records from the right side receive `null` values. | |
| **Right Join** | **Prioritizes the right Data Frame**. Returns all matching records plus **all remaining records from the right Data Frame**. Non-matching records from the left side receive `null` values. | |
| **Anti Join** | A special join that fetches only those records from the first Data Frame (DF1) that are **not matched** in the second Data Frame (DF2). This is **not available in SQL** as a keyword. | |

---

## 7. Window Functions

Window functions perform **special row-level calculations** and always require the **`over()`** clause.

| Function | Ranking Output | Difference from Other Ranks | Sources |
| :--- | :--- | :--- | :--- |
| **`row_number()`** | Generates a **sequential, unique number** (1, 2, 3...) for every record, regardless of duplicates. | Used to generate a surrogate key or remove duplicates. | |
| **`rank()`** | Assigns ranks, but **skips ranks** after encountering duplicates (e.g., 1, 1, 1, **7**, 7...). | The next rank value depends on the *count* of preceding rows. | |
| **`dense_rank()`** | Assigns ranks, but **does not skip ranks** after duplicates (e.g., 1, 1, 1, **2**, 2...). | Continues the original numerical flow regardless of preceding counts. | |
| **Cumulative Sum** | Calculates a running total by adding row-by-row. | Achieved by fusing the `sum()` function with the `over()` clause and defining a **Frame Clause**. | |
| **Frame Clause** | Defines the row boundaries for the window (e.g., for cumulative sum). | Uses `.rowsBetween(Window.unboundedPreceding, Window.currentRow)` to calculate the sum from the first record up to the current row. | |
| **Total Sum** | Calculates the total sum of the column in every record. | Uses `Window.unboundedFollowing` as the upper boundary: `.rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)`. | |

---

## 8. Date and String Functions

| Function | Purpose | Related Concept | Sources |
| :--- | :--- | :--- | :--- |
| **`current_date()`** | Provides the current date. | Used to create a new column with the current date. | |
| **`date_add(col, days)`** | Adds a specified number of days to a date column. | Can be used to subtract days by passing a negative integer (e.g., `-7`). | |
| **`date_diff(end, start)`** | Finds the interval (number of days) between two date columns. | End date should be specified first. | |
| **`date_format(col, format)`** | Changes the format of a date column (e.g., from YYYY-MM-DD to DD/MM/YYYY). | | |
| **`initcap(col)`** | Converts the first letter of each word to uppercase. | Similar to the **`proper` function in Excel**. | |
| **`lower(col)` / `upper(col)`** | Converts string text to lowercase or uppercase. | Useful for ensuring consistency before joins. | |
| **`split(col, delimiter)`** | Splits a string column based on a delimiter (e.g., space) into an **array (list)**. | Elements can be fetched using **indexing** (starting at 0). | |
| **`explode(col)`** | Transforms an array/list column by creating a **new row for each element** in the array. | Used to break a list down into individual entities. | |
| **`array_contains(col, "value")`** | Checks if a specific value exists within an array/list column, returning a Boolean flag (`True` or `False`). | | |

---

## 9. User Defined Functions (UDFs)

| Concept | Description | Sources |
| :--- | :--- | :--- |
| **Purpose** | Used to perform transformations that cannot be achieved easily using existing PySpark functions. | |
| **Creation** | Involves two steps: 1. Creating a standard Python function. 2. Registering it as a PySpark function using the **`UDF()`** command. | |
| **Recommendation** | **Should be avoided due to performance issues**. | |
| **Performance Issue** | The worker node's Java Virtual Machine (JVM) must invoke a separate **Python interpreter** to execute the function, increasing resource usage and slowing performance. | |
```
